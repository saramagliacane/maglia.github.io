@inproceedings{lippe2023causal,
    title        = {Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems},
    author       = {Phillip Lippe and Sara Magliacane and Sindy L{\"o}we and Yuki M Asano and Taco Cohen and Efstratios Gavves},
    year         = 2023,
    booktitle    = {The Eleventh International Conference on Learning Representations},
    url          = {https://openreview.net/forum?id=itZ6ggvMnzS},
    abbrev = {ICLR},
    code = {https://github.com/phlippe/CITRIS},
    pdf ={https://openreview.net/pdf?id=itZ6ggvMnzS}
}
@inproceedings{feng2022factored,
  doi = {10.48550/ARXIV.2203.16582},
  html = {https://arxiv.org/abs/2203.16582},
  author = {Feng, Fan and Huang, Biwei and Zhang, Kun and Magliacane, Sara}, 
  title = {Factored Adaptation for Non-Stationary Reinforcement Learning},
  abstract = {Dealing with non-stationarity in environments (e.g., in the transition dynamics) and objectives (e.g., in the reward functions) is a challenging problem that is crucial in real-world applications of reinforcement learning (RL). While most current approaches model the changes as a single shared embedding vector, we leverage insights from the recent causality literature to model non-stationarity in terms of individual latent change factors, and causal graphs across different environments. In particular, we propose Factored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption approach that learns jointly both the causal structure in terms of a factored MDP, and a factored representation of the individual time-varying change factors. We prove that under standard assumptions, we can completely recover the causal graph representing the factored transition and reward function, as well as a partial structure between the individual change factors and the state components. Through our general framework, we can consider general non-stationary scenarios with different function types and changing frequency, including changes across episodes and within episodes. Experimental results demonstrate that FANS-RL outperforms existing approaches in terms of return, compactness of the latent state representation, and robustness to varying degrees of non-stationarity.},
  booktitle = {Advances in Neural Information Processing Systems},
  abbr={NeurIPS},
  year = {2022},
  code ={https://github.com/ffeng1996/Factored-Nonstationary-RL},
  pdf = {https://arxiv.org/pdf/2203.16582.pdf}
}



@inproceedings{pmlr-v162-lippe22a,
	abstract = {Understanding the latent causal factors of a dynamical system from visual observations is considered a crucial step towards agents reasoning in complex environments. In this paper, we propose CITRIS, a variational autoencoder framework that learns causal representations from temporal sequences of images in which underlying causal factors have possibly been intervened upon. In contrast to the recent literature, CITRIS exploits temporality and observing intervention targets to identify scalar and multidimensional causal factors, such as 3D rotation angles. Furthermore, by introducing a normalizing flow, CITRIS can be easily extended to leverage and disentangle representations obtained by already pretrained autoencoders. Extending previous results on scalar causal factors, we prove identifiability in a more general setting, in which only some components of a causal factor are affected by interventions. In experiments on 3D rendered image sequences, CITRIS outperforms previous methods on recovering the underlying causal variables. Moreover, using pretrained autoencoders, CITRIS can even generalize to unseen instantiations of causal factors, opening future research areas in sim-to-real generalization for causal representation learning.},
	author = {Lippe, Phillip and Magliacane, Sara and L{\"o}we, Sindy and Asano, Yuki M and Cohen, Taco and Gavves, Stratis},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	pages = {13557--13603},
	pdf = {https://proceedings.mlr.press/v162/lippe22a/lippe22a.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {{CITRIS}: Causal Identifiability from Temporal Intervened Sequences},
	url = {https://proceedings.mlr.press/v162/lippe22a.html},
	volume = {162},
	year = {2022},
	abbr={ICML},
	code ={https://github.com/phlippe/CITRIS},
	html = {https://proceedings.mlr.press/v162/lippe22a.html}}


@inproceedings{huang2022adarl,
title={Ada{RL}: What, Where, and How to Adapt in Transfer Reinforcement Learning},
abstract ={One practical challenge in reinforcement learning (RL) is how to make quick adaptations when faced with new environments. In this paper, we propose a principled framework for adaptive RL, called \textit{AdaRL}, that adapts reliably and efficiently to changes across domains with a few samples from the target domain, even in partially observable environments. Specifically, we leverage a parsimonious graphical representation that characterizes structural relationships over variables in the RL system. Such graphical representations provide a compact way to encode what and where the changes across domains are, and furthermore inform us with a minimal set of changes that one has to consider for the purpose of policy adaptation. We show that by explicitly leveraging this compact representation to encode changes, we can efficiently adapt the policy to the target domain, in which only a few samples are needed and further policy optimization is avoided. We illustrate the efficacy of AdaRL through a series of experiments that vary factors in the observation, transition, and reward functions for Cartpole and Atari games.},
author={Biwei Huang and Fan Feng and Chaochao Lu and Sara Magliacane and Kun Zhang},
booktitle={International Conference on Learning Representations},
year={2022},
abbr={ICLR},
html={https://openreview.net/forum?id=8H5bpVwvt5},
pdf={https://openreview.net/pdf?id=8H5bpVwvt5},
code = {https://github.com/Adaptive-RL/AdaRL-code}
}


@inproceedings{squires2022active,
	author = {Squires, Chandler and Magliacane, Sara and Greenewald, Kristjan and Katz, Dmitriy and Kocaoglu, Murat and Shanmugam, Karthikeyan},
	booktitle = {Advances in Neural Information Processing Systems},
	abstract = {A growing body of work has begun to study intervention design for efficient
structure learning of causal directed acyclic graphs (DAGs). A typical setting is
a causally sufficient setting, i.e. a system with no latent confounders, selection
bias, or feedback, when the essential graph of the observational equivalence class
(EC) is given as an input and interventions are assumed to be noiseless. Most
existing works focus on worst-case or average-case lower bounds for the number
of interventions required to orient a DAG. These worst-case lower bounds only
establish that the largest clique in the essential graph could make it difficult to
learn the true DAG. In this work, we develop a universal lower bound for singlenode interventions that establishes that the largest clique is always a fundamental
impediment to structure learning. Specifically, we present a decomposition of a
DAG into independently orientable components through directed clique trees and
use it to prove that the number of single-node interventions necessary to orient any
DAG in an EC is at least the sum of half the size of the largest cliques in each chain
component of the essential graph. Moreover, we present a two-phase intervention
design algorithm that, under certain conditions on the chordal skeleton, matches
the optimal number of interventions up to a multiplicative logarithmic factor in the
number of maximal cliques. We show via synthetic experiments that our algorithm
can scale to much larger graphs than most of the related work and achieves better
worst-case performance than other scalable approaches.},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	pages = {21500--21511},
	publisher = {Curran Associates, Inc.},
	title = {Active Structure Learning of Causal DAGs via Directed Clique Trees},
	html = {https://proceedings.neurips.cc/paper/2020/file/f57bd0a58e953e5c43cd4a4e5af46138-Paper.pdf},
	volume = {33},
	year = {2020},
	abbr={NeurIPS},
	code={https://github.com/csquires/dct-policy},
	pdf = {https://proceedings.neurips.cc/paper/2020/file/f57bd0a58e953e5c43cd4a4e5af46138-Paper.pdf}}



@inproceedings{magliacane2018domain,
	author = {Magliacane, Sara and van Ommen, Thijs and Claassen, Tom and Bongers, Stephan and Versteeg, Philip and Mooij, Joris M},
	abstract= {An important goal common to domain adaptation and causal inference is to make accurate predictions when the distributions for the source (or training) domain(s) and target (or test) domain(s) differ. In many cases, these different distributions can be modeled as different contexts of a single underlying system, in which each distribution corresponds to a different perturbation of the system, or in causal terms, an intervention. We focus on a class of such causal domain adaptation problems, where data for one or more source domains are given, and the task is to predict the distribution of a certain target variable from measurements of other variables in one or more target domains. We propose an approach for solving these problems that exploits causal inference and does not rely on prior knowledge of the causal graph, the type of interventions or the intervention targets. We demonstrate our approach by evaluating a possible implementation on simulated and real world data.},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions},
	html = {https://proceedings.neurips.cc/paper/2018/file/39e98420b5e98bfbdc8a619bef7b8f61-Paper.pdf},
	volume = {31},
	year = {2018},
  booktitle = {Advances in Neural Information Processing Systems},
  abbr={NeurIPS},
  code ={https://github.com/caus-am/dom_adapt},
	pdf = {https://proceedings.neurips.cc/paper/2018/file/39e98420b5e98bfbdc8a619bef7b8f61-Paper.pdf}
	}


	
@article{10.5555/3455716.3455815,
	abstract = {The gold standard for discovering causal relations is by means of experimentation. Over the last decades, alternative methods have been proposed that can infer causal relations between variables from certain statistical patterns in purely observational data. We introduce Joint Causal Inference (JCI), a novel approach to causal discovery from multiple data sets from different contexts that elegantly unifies both approaches. JCI is a causal modeling framework rather than a specific algorithm, and it can be implemented using any causal discovery algorithm that can take into account certain background knowledge. JCI can deal with different types of interventions (e.g., perfect, imperfect, stochastic, etc.) in a unified fashion, and does not require knowledge of intervention targets or types in case of interventional data. We explain how several well-known causal discovery algorithms can be seen as addressing special cases of the JCI framework, and we also propose novel implementations that extend existing causal discovery methods for purely observational data to the JCI setting. We evaluate different JCI implementations on synthetic data and on ow cytometry protein expression data and conclude that JCI implementations can considerably outperform state-of-the-art causal discovery algorithms.},
	articleno = {99},
	author = {Mooij, Joris M. and Magliacane, Sara and Claassen, Tom},
	date-modified = {2022-10-27 14:36:30 +0200},
	issn = {1532-4435},
	issue_date = {January 2020},
	journal = {J. Mach. Learn. Res.},
	keywords = {interventions, causal inference, randomized controlled trials, observational and experimental data, causal discovery, causal modeling},
	month = {jun},
	number = {1},
	numpages = {108},
	publisher = {JMLR.org},
	title = {Joint Causal Inference from Multiple Contexts},
	volume = {21},
	year = {2020}}

